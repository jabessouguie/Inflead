{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker \n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "import botocore.config\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    user_agent_extra = 'dsoaws/1.0'\n",
    "    )\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\",\n",
    "                           region_name = region,\n",
    "                            config = config)\n",
    "s3 = boto3.Session().client(service_name=\"s3\",\n",
    "                           region_name = region, \n",
    "                           config = config)\n",
    "featurestore_runtime = boto3.Session().client(service_name = \"sagemaker-featurestore-runtime\",\n",
    "                                             region_name=region,\n",
    "                                             config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set S3 Source Location (Public S3 Bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_public_path_tsv =\"s3://amazon-reviews-pds/tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_public_path_tsv' (str)\n"
     ]
    }
   ],
   "source": [
    "%store s3_public_path_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set S3 Destination Location (Our Private S3 Bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-252915492200/amazon-reviews-pds/tsv\n"
     ]
    }
   ],
   "source": [
    "s3_private_path_tsv =\"s3://{}/amazon-reviews-pds/tsv\".format(bucket)\n",
    "print(s3_private_path_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_private_path_tsv' (str)\n"
     ]
    }
   ],
   "source": [
    "%store s3_private_path_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data from the Public S3 Bucket to our Private S3 Bucket in this Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz to s3://sagemaker-us-east-1-252915492200/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "copy: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz to s3://sagemaker-us-east-1-252915492200/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $s3_public_path_tsv $s3_private_path_tsv/ --exclude \"*\" --include \"amazon_reviews_us_Digital_Software_v1_00.tsv.gz\"\n",
    "!aws s3 cp --recursive $s3_public_path_tsv $s3_private_path_tsv/ --exclude \"*\" --include \"amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\"\n",
    "!aws s3 cp --recursive $s3_public_path_tsv $s3_private_path_tsv/ --exclude \"*\" --include \"amazon_reviews_us_Gift_Gard_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the Pipeline as an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing pipeline: BERT-pipeline-1651055982\n"
     ]
    }
   ],
   "source": [
    "%store -r pipeline_name\n",
    "try :\n",
    "    print(\"Using existing pipeline: {}\".format(pipeline_name))\n",
    "except NameError :\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_name = \"BERT-pipeline-{}\".format(timestamp)\n",
    "    print(\"Creating Pipeline Name:\",pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Pipeline Name: BERT-pipeline-1651066961\n"
     ]
    }
   ],
   "source": [
    "running_executions = 0\n",
    "completed_executions = 0\n",
    "\n",
    "try :\n",
    "    existing_pipeline_executions_response = sm.list_pipeline_execution(\n",
    "        PipelineName = pipeline_name,\n",
    "        SortOrder = \"Descending\"\n",
    "    )\n",
    "    if \"PipelineExecutionSummaries\" in existing_pipeline_execution_response.keys():\n",
    "        if len(existing_pipeline_execution_response[\"PipelineExecutionSummaries\"]) >0:\n",
    "            execution = existing_pipeline_execution_response[\"PipelineExecutionSummaries\"][0]\n",
    "            if \"PipelineExecutionSummaries\" in execution:\n",
    "                if execution[\"PipelineExecutionSummaries\"] == \"Executing\":\n",
    "                    running_executions = running_executions + 1\n",
    "                else :\n",
    "                    completed_executions = completed_executions + 1\n",
    "            print(\"[INFO] You have {} Pipeline execution(s) currently running and {} execution(s) completed\".format(\n",
    "            running_executions,completed_executions)\n",
    "                 )\n",
    "    else :\n",
    "        print(\"[OK] Please continues\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if running_executions ==0:\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_name = \"BERT-pipeline-{}\".format(timestamp)\n",
    "    print(\"Created Pipeline Name:\",pipeline_name)\n",
    "            \n",
    "    \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-pipeline-1651066961\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pipeline_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store pipeline_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.trial import Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pipeline_trial_name\n",
    "\n",
    "try:\n",
    "    pipeline_trial_name\n",
    "except NameError:\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_trial = Trial.create(\n",
    "        trial_name=\"Trial-{}\".format(timestamp),experiment_name = pipeline_experiment_name, sagemaker_boto_client =sm\n",
    "    )\n",
    "    pipeline_trial_name = pipeline_trial.trial_name\n",
    "    print(\"Created Trial Name :{}\".format(pipeline_trial_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial-1650926425\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pipeline_trial_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store pipeline_trial_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters to Parametrize Pipeline Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define Workflow Parameters by which we can parametrize our Pipeline and vary the values injected and used in Pipeline executions and schedules without to modify the Pipeline defintion.\n",
    "The supported parameter types include :\n",
    "- ParameterString : representing a str Python type\n",
    "- ParameterInteger :representing a int Python type\n",
    "- ParameterFloat :representing a float Python type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import(\n",
    "    ParameterString ,\n",
    "    ParameterInteger,\n",
    "    ParameterFloat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bert_pipeline/biography.csv\n"
     ]
    }
   ],
   "source": [
    "raw_input_data_s3_url = \"/bert_pipeline/biography.csv\"\n",
    "print(raw_input_data_s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-04 08:53:03 aws-athena-query-results-252915492200-us-east-1\n",
      "2022-04-04 09:23:03 aws-athena-query-results-us-east-1-252915492200\n",
      "2022-04-04 08:41:42 aws-cloudtrail-logs-252915492200-3b317ae5\n",
      "2022-04-22 16:13:30 sagemaker-project-p-co7l6mjhioym\n",
      "2022-04-22 17:06:57 sagemaker-project-p-naedfukawvvw\n",
      "2022-04-20 12:50:25 sagemaker-project-p-uiyuvpon0dkv\n",
      "2022-04-22 17:11:02 sagemaker-project-p-ydr3lke0ekeu\n",
      "2022-04-20 12:38:25 sagemaker-studio-252915492200-8wcjntn99wb\n",
      "2022-04-20 12:39:29 sagemaker-studio-252915492200-kud7xcrx35\n",
      "2022-04-25 21:21:12 sagemaker-us-east-1-252915492200\n",
      "2022-04-22 17:34:01 sagemaker-us-west-2-252915492200\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "input_data = ParameterString(\n",
    "        name=\"InputData\",\n",
    "        default_value = raw_input_data_s3_url,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name = \"ProcessingInstanceCount\",\n",
    "    default_value =1,\n",
    ")\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name = \"ProcessingInstanceType\",\n",
    "    default_value = \"ml.c5.2xlarge\",\n",
    ")\n",
    "\n",
    "max_seq_length = ParameterInteger(\n",
    "    name = \"MaxSeqLength\",\n",
    "    default_value = 64,\n",
    ")\n",
    "\n",
    "balance_dataset = ParameterString(\n",
    "    name = \"BalanceDataset\",\n",
    "    default_value = \"True\",\n",
    ")\n",
    "\n",
    "train_split_percentage = ParameterFloat(\n",
    "    name = \"TrainSplitPercentage\",\n",
    "    default_value = 0.90,\n",
    ")\n",
    "\n",
    "validation_split_percentage = ParameterFloat(\n",
    "    name = \"ValidationSplitPercentage\",\n",
    "    default_value = 0.05,\n",
    ")\n",
    "\n",
    "test_split_percentage = ParameterFloat(\n",
    "    name = \"ValidationSplitPercentage\",\n",
    "    default_value = 0.05,\n",
    ")\n",
    "\n",
    "feature_store_offline_prefix = ParameterString(\n",
    "    name = \"FeaturesStoreOfflinePrefix\",\n",
    "    default_value = \"reviews-features-store-\" + str(timestamp),\n",
    ")\n",
    "\n",
    "feature_group_name = ParameterString(\n",
    "    name = \"FeaturesGroupName\",\n",
    "    default_value = \"reviews-features-group-\" + str(timestamp),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of an SKlearnProcessor processor and we use that in our ProcessingStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version= \"0.23-1\",\n",
    "    role = role,\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = processing_instance_count,\n",
    "    env={\"AWS_DEFAULT_REGION\":region})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessingStep(name='Processing', display_name=None, description=None, step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processing_inputs = [\n",
    "    ProcessingInput(\n",
    "        input_name = \"raw-input-data\",\n",
    "        source = input_data,\n",
    "        destination = \"/opt/ml/processing/input/data/\",\n",
    "        s3_data_distribution_type = \"ShardedByS3Key\",\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name = \"bert-train\",\n",
    "        s3_upload_mode =\"EndOfJob\",\n",
    "        source = \"/opt/ml/processing/output/bert/train\",\n",
    "    ),\n",
    "        \n",
    "    ProcessingOutput(\n",
    "        output_name = \"bert-validation\",\n",
    "        s3_upload_mode = \"EndofJob\",\n",
    "        source  = \"/opt/ml/processing/output/bert/validation\"\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name = \"bert-test\",\n",
    "        s3_upload_mode = \"EndofJob\",\n",
    "        source  = \"/opt/ml/processing/output/bert/test\"\n",
    "    ),\n",
    "]\n",
    "processing_step = ProcessingStep(\n",
    "    name = \"Processing\",\n",
    "    code = \"preprocessing.py\",\n",
    "    processor = processor,\n",
    "    inputs = processing_inputs,\n",
    "    outputs= processing_outputs,\n",
    "    job_arguments = [\n",
    "        \"--train-split-percentage\",\n",
    "        str(train_split_percentage.default_value),\n",
    "        \"--validation-split-percentage\",\n",
    "        str(validation_split_percentage.default_value),\n",
    "        \"--test-split-percentage\",\n",
    "        str(test_split_percentage.default_value),\n",
    "        \"--max-seq-length\",\n",
    "        str(max_seq_length.default_value),\n",
    "        \"--balance-dataset\",\n",
    "        str(balance_dataset.default_value),\n",
    "        \"--feature-store-offline-prefix\",\n",
    "        str(feature_store_offline_prefix.default_value),\n",
    "        \"--feature-group-name\",\n",
    "        str(feature_group_name.default_value),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = ParameterString(name=\"TrainInstanceType\", default_value = \"ml.c5.9xlarge\")\n",
    "train_instance_count = ParameterInteger(name=\"TrainInstanceCount\", default_value = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Hyper-Parameters \n",
    "Note that max_seq_length is re-used from the processing hyper-parameters above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = ParameterInteger(name=\"Epochs\", default_value=1)\n",
    "\n",
    "learning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.00001)\n",
    "\n",
    "epsilon = ParameterFloat(name=\"Epsilon\", default_value=0.00000001)\n",
    "\n",
    "train_batch_size = ParameterInteger(name=\"TrainBatchSize\", default_value=128)\n",
    "\n",
    "validation_batch_size = ParameterInteger(name=\"ValidationBatchSize\", default_value=128)\n",
    "\n",
    "test_batch_size = ParameterInteger(name=\"TestBatchSize\", default_value=128)\n",
    "\n",
    "train_steps_per_epoch = ParameterInteger(name=\"TrainingStepPerEpoch\", default_value=50)\n",
    "\n",
    "validation_steps = ParameterInteger(name=\"ValidationSteps\",default_value=50)\n",
    "\n",
    "test_steps = ParameterInteger(name=\"TestSteps\",default_value=50)\n",
    "\n",
    "train_volume_size = ParameterInteger(name = \"TrainVolumeSize\",default_value=256)\n",
    "\n",
    "use_xla= ParameterString(\n",
    "    name =\"UseXLA\",\n",
    "    default_value = \"True\",\n",
    ")\n",
    "\n",
    "use_map = ParameterString(\n",
    "    name = \"UseAMP\",\n",
    "    default_value = \"True\",\n",
    ")\n",
    "\n",
    "freeze_bert_layer = ParameterString(\n",
    "    name = \"freezeBERTlayer\",\n",
    "    default_value = \"False\",\n",
    ")\n",
    "\n",
    "enable_sagemaker_debugger = ParameterString(\n",
    "    name = \"EnableSageMakerDebugger\",\n",
    "    default_value = \"False\"\n",
    ")\n",
    "\n",
    "enable_checkpointing = ParameterString(\n",
    "    name = \"EnableCheckpointing\",\n",
    "    default_value = \"False\",\n",
    ")\n",
    "\n",
    "enable_tensorboard = ParameterString(\n",
    "    name = \"EnableTensorboard\",\n",
    "    default_value = \"False\"\n",
    ")\n",
    "\n",
    "input_mode = ParameterString(\n",
    "    name = \"InputMode\",\n",
    "    default_value = \"File\",\n",
    "    )\n",
    "\n",
    "run_test = ParameterString(\n",
    "    name = \"RunTest\",\n",
    "    default_value = \"False\",\n",
    ")\n",
    "\n",
    "run_validation = ParameterString(\n",
    "    name = \"RunValidation\",\n",
    "    default_value = \"False\",\n",
    ")\n",
    "\n",
    "run_sample_predictions = ParameterString(\n",
    "    name = \"RunSamplePredictions\",\n",
    "    default_value = \"False\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Metrics to Track Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "    {\"Name\":\"train:loss\", \"Regex\":\"loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\":\"train:accuracy\", \"Regex\":\"accuracy: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\":\"validation:loss\", \"Regex\":\"val_loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\":\"validation:accuracy\", \"Regex\":\"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Debugger and Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import DebuggerHookConfig\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    s3_output_path = \"s3://{}\".format(bucket),\n",
    ")\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis = 500,\n",
    "    framework_profile_params = FrameworkProfile(local_path=\"/opt/ml/output/profile\",start_step=5, num_steps=10),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules =[ProfilerRule.sagemaker(rule_configs.ProfilerReport())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the estimator \n",
    "We configure an Estimator and the input dataset. A typical training script loads data from the input channels, configures training with hyperparameters, train a model and saves the model to \"model_dir\" so that it can be hosted later.\n",
    "We also specify the model_path where the models from training will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "evaluation_report = PropertyFile(name=\"EvaluationReport\",output_name = \"metrics\",path=\"evaluation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point = \"evaluation.py\",\n",
    "    #source_dir = \"bert_pipeline/\",\n",
    "    role = role,\n",
    "    instance_count = train_instance_count, # Make sure you have at least this number of input files \n",
    "    instance_type = train_instance_type,\n",
    "    volume_size = train_volume_size,\n",
    "    py_version = \"py37\",\n",
    "    framework_version =\"2.3.1\",\n",
    "    hyperparameters={\n",
    "        \"epochs\":epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"validation_batch_size\": train_batch_size,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"train_steps_per_epoch\":train_steps_per_epoch,\n",
    "        \"validation_steps\": validation_steps,\n",
    "        \"test_steps\": test_steps,\n",
    "        \"usa_xla\": use_xla,\n",
    "        \"use_map\": use_map,\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"freeze_bert_layer\": freeze_bert_layer,\n",
    "        \"enable_sagemaker_debugger\": enable_sagemaker_debugger,\n",
    "        \"enable_checkpointing\":enable_checkpointing,\n",
    "        \"enable_tensorboard\":enable_tensorboard,\n",
    "        \"run_validation\" : run_validation,\n",
    "        \"run_test\":run_test,\n",
    "        \"run_sample_predictions\": run_sample_predictions,\n",
    "        \n",
    "    },\n",
    "    input_mode = input_mode,\n",
    "    metrics_definitions = metrics_definitions,\n",
    "    debugger_hook_config = debugger_hook_config,\n",
    "    profiler_config = profiler_config,\n",
    "    rules = rules \n",
    "    \n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingStep(name='Train', display_name=None, description=None, step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name = \"Train\",\n",
    "    estimator = estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "        s3_data= processing_step.properties.ProcessingOutputConfig.Outputs[\"train-bert\"].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data = processing_step.properties.ProcessingOutputConfig.Outputs[\"bert-validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data = processing_step.properties.ProcessingOutputConfig.Outputs[\"bert-test\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \n",
    "    },\n",
    "    #cache_config =cache_config,\n",
    ")\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Step\n",
    "\n",
    "First, we develop an evaluation script that will be specified in a Processing step that will perform the model evaluation.\n",
    "The evaluation script \"evaluation.py\" takes the trained_model and the test dataset as input, and produce a JSON file containing  classification evaluation metrics such as accuracy.\n",
    "After the pipeline execution, we will examine the resulting \"evaluation.json\" for analysis.\n",
    "\n",
    "The evaluation script :\n",
    "- loads in the model\n",
    "- reads in the test data\n",
    "- issues a bunch of predictions against the test data\n",
    "- build a classification report, including the accuracy\n",
    "- save the evaluation report to the evaluation directory\n",
    "\n",
    "Next we create an instance of a \"ScriptProcessor\" processor and we use that in our ProcessingStep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version = \"0.23-1\",\n",
    "    role = role,\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = processing_instance_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_step = ProcessingStep(\n",
    "    name = \"EvaluateModel\",\n",
    "    processor = evaluation_processor,\n",
    "    code = \"evaluation.py\",\n",
    "    inputs = [\n",
    "        ProcessingInput(\n",
    "            source= training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination = \"/opt/ml/processing/input/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source= processing_step.properties.ProcessingInputs[\"raw-input-data\"].S3Input.S3Uri,\n",
    "            destination = \"/opt/ml/processing/input/data\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(\n",
    "        output_name = \"metrics\", s3_upload_mode=\"EndOfJob\", source =\"/opt/ml/processing/output/metrics/\"\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--max-seq-length\",\n",
    "        str(max_seq_length.default_value)\n",
    "    ],\n",
    "    property_files = [evaluation_report]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.model_metrics.ModelMetrics object at 0x7f339072a5d0>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics= MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "        evaluation_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "    ),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    ")\n",
    "print(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model Step\n",
    "We use the estimator instance that was used for the training step to construct an instance of RegisterModel. The result of executing RegisterModel in a pipeline is a Model Package. A Model Package is a reusable model artifacts abstraction that packages all ingredients necessary for inference. Primarly, it consists of an inference specification that defines the inference image to use along with an optional model weights location.\n",
    "\n",
    "A Model Package Group is a collection of ModelPackages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\",default_value =\"PendingManualApproval\")\n",
    "deploy_instance_type = ParameterString(name =\"DeployInstanceType\", default_value =\"ml.m5.4xlarge\")\n",
    "deploy_instance_count = ParameterInteger(name =\"DeployInstanceCount\", default_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-reviews-1651066963\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = f\"BERT-reviews-{timestamp}\"\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.1-cpu\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework =\"tensorflow\",\n",
    "    region=region,\n",
    "    version =\"2.3.1\",\n",
    "    instance_type = deploy_instance_type,\n",
    "    image_scope = \"inference\",\n",
    ")\n",
    "\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name =\"RegisterModel\",\n",
    "    estimator =estimator,\n",
    "    image_uri = inference_image_uri, # We have to specify, by default it's using he training image \n",
    "    model_data = training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types = [\"application/jsonlines\"],\n",
    "    response_types = [\"application/jsonlines\"],\n",
    "    inference_instances = deploy_instance_type,\n",
    "    transform_instances = [\"ml.m5.4xlarge\"],\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    approval_status = model_approval_status,\n",
    "    model_metrics = model_metrics,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model for Deployment Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = \"bert-model-{}\".format(timestamp)\n",
    "\n",
    "model = Model(\n",
    "    name = model_name,\n",
    "    image_uri = inference_image_uri,\n",
    "    model_data = training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session = sess,\n",
    "    role = role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "create_inputs = CreateModelInput(\n",
    "    instance_type=deploy_instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "create_step = CreateModelStep(\n",
    "    name=\"CreateModel\",\n",
    "    model=model,\n",
    "    inputs =create_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Deployment Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we do the following:\n",
    "- define a \"ConditionGreaterThan\" on the accuracy value found in the output of the evaluation step\n",
    "- use the condition in the list of the conditions in a \"ConditionStep\"\n",
    "- pass the \"RegisterModel\" step collection into the \"if_steps\" of the \"ConditionStep\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The class JsonGet has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet)\n",
    "\n",
    "min_accuracy_value = ParameterFloat(name=\"MinAccuracyValue\",default_value=0.90)\n",
    "\n",
    "minimum_accuracy_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet[\n",
    "    step=evaluation_step,\n",
    "    property_file=evaluation_report,\n",
    "    json_path=\"metrics.accuracy.value\",\n",
    "    ],\n",
    "    right=min_accuracy_value,\n",
    ")\n",
    "minimum_accuracy_condition_step = ConditionStep(\n",
    "    name=\"AccuracyCondition\", \n",
    "    conditions=[minimum_accuracy_condition],\n",
    "    if_steps=[register_step,create_step], # success, continue with model registration\n",
    "    else_steps=[], #fail, end the pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "Let's tie all up into a workflow pipeline so we can execute it and even schedule it.\n",
    "A pipeline requires a name, parameters, and steps. Names must be unique within an (account, region) pair so we tack on the timestamp to the name.\n",
    "Note :\n",
    "- All the parameters used in the definitions must be present.\n",
    "- Steps passed into the pipeline need to be in the order of execution. The SageMaker Worflow service will resolve the data dependency DAG as steps the execution complete.\n",
    "- Steps must be unique to either pipeline step list or a single condition step if/else list.\n",
    "\n",
    "\n",
    "\n",
    "### Submit the pipeline to SageMaker for Execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the job defined in the steps.\n",
    "\n",
    "### Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreatePipeline operation: Unable to parse pipeline definition. Expecting start of Json Array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-72df690e02d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0msagemaker_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_arn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PipelineArn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created pipeline with name {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     def _create_args(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    400\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreatePipeline operation: Unable to parse pipeline definition. Expecting start of Json Array."
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "existing_pipelines = 0\n",
    "\n",
    "existing_pipelines_response = sm.list_pipelines(\n",
    "    PipelineNamePrefix=pipeline_name,\n",
    "    SortOrder=\"Descending\",\n",
    ")\n",
    "\n",
    "if \"PipelineSummaries\" in existing_pipelines_response.keys():\n",
    "    if len(existing_pipelines_response[\"PipelineSummaries\"])>0:\n",
    "        existing_pipelines= existing_pipelines + 1\n",
    "        print(\"[INFO] You already have created {} pipeline with name {}\".format(existing_pipelines,pipeline_name))\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "if existing_pipelines ==0: # Only create the pipeline one time\n",
    "    pipeline = Pipeline(\n",
    "        name = pipeline_name,\n",
    "        parameters = [\n",
    "            input_data,\n",
    "            processing_instance_count,\n",
    "            processing_instance_type,\n",
    "            max_seq_length,\n",
    "            balance_dataset,\n",
    "            train_split_percentage,\n",
    "            validation_split_percentage,\n",
    "            test_split_percentage,\n",
    "            feature_store_offline_prefix,\n",
    "            feature_group_name,\n",
    "            train_instance_type,\n",
    "            train_instance_count,\n",
    "            epochs,\n",
    "            learning_rate,\n",
    "            epsilon,\n",
    "            train_batch_size,\n",
    "            validation_batch_size,\n",
    "            test_batch_size,\n",
    "            train_steps_per_epoch,\n",
    "            validation_steps,\n",
    "            test_steps,\n",
    "            train_volume_size,\n",
    "            use_xla,\n",
    "            use_map,\n",
    "            freeze_bert_layer,\n",
    "            enable_sagemaker_debugger,\n",
    "            enable_checkpointing,\n",
    "            enable_tensorboard,\n",
    "            input_mode,\n",
    "            run_validation,\n",
    "            run_test,\n",
    "            run_sample_predictions,\n",
    "            min_accuracy_value,\n",
    "            model_approval_status,\n",
    "            deploy_instance_type,\n",
    "            deploy_instance_count, \n",
    "        ],\n",
    "        steps=[processing_step,training_step,evaluation_step,minimum_accuracy_condition_step],\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "    pipeline.create(role_arn=role)[\"PipelineArn\"]\n",
    "    print(\"Created pipeline with name {}\".format(pipeline_name))\n",
    "else :\n",
    "    print(\"Error\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
